#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Gemini APIë¥¼ ì‚¬ìš©í•œ ë¸”ë¡œê·¸ ì½˜í…ì¸  í’ˆì§ˆ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import json
import sys
import requests
from dotenv import load_dotenv
from generate_blog import load_prompt_template, render_prompt, call_gemini_api

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ì„¤ì •
QUALITY_THRESHOLD = float(os.getenv("QUALITY_THRESHOLD", "7.0"))
API_BASE_URL = os.getenv("API_BASE_URL", "http://localhost:8080")

def evaluate_content(content):
    """
    ìƒì„±ëœ ë¸”ë¡œê·¸ ì½˜í…ì¸ ë¥¼ í‰ê°€

    Args:
        content: í‰ê°€í•  ë¸”ë¡œê·¸ ì½˜í…ì¸  (dict)

    Returns:
        í‰ê°€ ê²°ê³¼ (JSON íŒŒì‹±ë¨)
    """
    # í‰ê°€ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    template_path = os.path.join(
        os.path.dirname(__file__),
        '..',
        'prompts',
        'quality_evaluation.txt'
    )
    template = load_prompt_template(template_path)

    # í‰ê°€í•  ì½˜í…ì¸ ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
    content_json = json.dumps(content, ensure_ascii=False, indent=2)

    # í”„ë¡¬í”„íŠ¸ ë Œë”ë§
    prompt_data = {
        'generated_content': content_json
    }
    prompt = render_prompt(template, prompt_data)

    # API í˜¸ì¶œ
    print(f"\nğŸ“Š ì½˜í…ì¸  í’ˆì§ˆ í‰ê°€ ì¤‘...")
    response_text = call_gemini_api(prompt)

    # JSON íŒŒì‹±
    try:
        evaluation = json.loads(response_text)
        print(f"âœ… í‰ê°€ ì™„ë£Œ!")
        return evaluation
    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        print(f"ì‘ë‹µ ë‚´ìš©: {response_text[:500]}...")
        raise Exception("API ì‘ë‹µì´ ìœ íš¨í•œ JSONì´ ì•„ë‹™ë‹ˆë‹¤.")

def print_evaluation_summary(evaluation):
    """í‰ê°€ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
    print("\n" + "="*60)
    print("ğŸ“ˆ í‰ê°€ ê²°ê³¼ ìš”ì•½")
    print("="*60)

    # ì ìˆ˜ ì¶œë ¥
    scores = evaluation.get('scores', {})
    print("\nğŸ“Š í•­ëª©ë³„ ì ìˆ˜:")
    print(f"  - ì‹ í•™ì  ì •í™•ì„±: {scores.get('theological_accuracy', 0)}/10")
    print(f"  - ì½˜í…ì¸  êµ¬ì¡°: {scores.get('content_structure', 0)}/10")
    print(f"  - ë…ì ì°¸ì—¬ë„: {scores.get('engagement', 0)}/10")
    print(f"  - ê¸°ìˆ ì  í’ˆì§ˆ: {scores.get('technical_quality', 0)}/10")
    print(f"  - SEO ìµœì í™”: {scores.get('seo_optimization', 0)}/10")

    # ê°€ì¤‘ì¹˜ ì ìš© ì ìˆ˜
    weighted = evaluation.get('weighted_breakdown', {})
    print("\nâš–ï¸  ê°€ì¤‘ì¹˜ ì ìš© ì ìˆ˜:")
    print(f"  - ì‹ í•™ì  ì •í™•ì„± (30%): {weighted.get('theological_accuracy', 0):.2f}")
    print(f"  - ì½˜í…ì¸  êµ¬ì¡° (25%): {weighted.get('content_structure', 0):.2f}")
    print(f"  - ë…ì ì°¸ì—¬ë„ (20%): {weighted.get('engagement', 0):.2f}")
    print(f"  - ê¸°ìˆ ì  í’ˆì§ˆ (15%): {weighted.get('technical_quality', 0):.2f}")
    print(f"  - SEO ìµœì í™” (10%): {weighted.get('seo_optimization', 0):.2f}")

    # ì´ì 
    total_score = evaluation.get('total_score', 0)
    print(f"\nğŸ¯ ì´ì : {total_score:.1f}/10.0")
    print(f"   ìµœì†Œ ê¸°ì¤€: {QUALITY_THRESHOLD}/10.0")

    # í”¼ë“œë°±
    feedback = evaluation.get('feedback', {})

    if feedback.get('strengths'):
        print("\nâœ… ì¥ì :")
        for strength in feedback['strengths']:
            print(f"  â€¢ {strength}")

    if feedback.get('improvements'):
        print("\nğŸ“ ê°œì„ ì‚¬í•­:")
        for improvement in feedback['improvements']:
            print(f"  â€¢ {improvement}")

    if feedback.get('critical_issues'):
        print("\nğŸš¨ ì¹˜ëª…ì  ë¬¸ì œ:")
        for issue in feedback['critical_issues']:
            print(f"  â€¢ {issue}")

    # ê¶Œì¥ì‚¬í•­
    recommendation = evaluation.get('recommendation', 'unknown')
    confidence = evaluation.get('confidence', 'unknown')

    print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­: {recommendation}")
    print(f"   ì‹ ë¢°ë„: {confidence}")

    print("="*60 + "\n")

def should_publish(evaluation):
    """
    ë°œí–‰ ì—¬ë¶€ íŒë‹¨

    Args:
        evaluation: í‰ê°€ ê²°ê³¼

    Returns:
        (should_publish: bool, reason: str)
    """
    total_score = evaluation.get('total_score', 0)
    scores = evaluation.get('scores', {})
    feedback = evaluation.get('feedback', {})
    recommendation = evaluation.get('recommendation', 'reject')

    # ì¹˜ëª…ì  ë¬¸ì œ ì²´í¬
    if feedback.get('critical_issues'):
        return False, f"ì¹˜ëª…ì  ë¬¸ì œ ë°œê²¬: {len(feedback['critical_issues'])}ê°œ"

    # í•„ìˆ˜ í†µê³¼ ê¸°ì¤€ ì²´í¬
    theological_accuracy = scores.get('theological_accuracy', 0)
    technical_quality = scores.get('technical_quality', 0)

    if theological_accuracy < 6.0:
        return False, f"ì‹ í•™ì  ì •í™•ì„± ë¯¸ë‹¬: {theological_accuracy}/10 (ìµœì†Œ 6.0 í•„ìš”)"

    if technical_quality < 7.0:
        return False, f"ê¸°ìˆ ì  í’ˆì§ˆ ë¯¸ë‹¬: {technical_quality}/10 (ìµœì†Œ 7.0 í•„ìš”)"

    # ì´ì  ì²´í¬
    if total_score < QUALITY_THRESHOLD:
        return False, f"ì´ì  ë¯¸ë‹¬: {total_score:.1f}/10 (ìµœì†Œ {QUALITY_THRESHOLD} í•„ìš”)"

    # ê¶Œì¥ì‚¬í•­ ì²´í¬
    if recommendation != "publish":
        return False, f"ê¶Œì¥ì‚¬í•­: {recommendation}"

    return True, "ëª¨ë“  ê¸°ì¤€ í†µê³¼"

def fetch_blog_from_api(blog_id):
    """
    APIì—ì„œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì¡°íšŒ

    Args:
        blog_id: ë¸”ë¡œê·¸ ID

    Returns:
        ë¸”ë¡œê·¸ ë°ì´í„° (dict)
    """
    url = f"{API_BASE_URL}/api/admin/blog/posts/{blog_id}"

    try:
        response = requests.get(url)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        raise

def save_evaluation_to_api(blog_id, evaluation):
    """
    í‰ê°€ ê²°ê³¼ë¥¼ APIë¡œ ì €ì¥

    Args:
        blog_id: ë¸”ë¡œê·¸ ID
        evaluation: í‰ê°€ ê²°ê³¼

    Returns:
        API ì‘ë‹µ (dict)
    """
    url = f"{API_BASE_URL}/api/admin/blog/posts/{blog_id}/evaluate"

    scores = evaluation.get('scores', {})

    payload = {
        "theological_accuracy": scores.get('theological_accuracy', 0),
        "content_structure": scores.get('content_structure', 0),
        "engagement": scores.get('engagement', 0),
        "technical_quality": scores.get('technical_quality', 0),
        "seo_optimization": scores.get('seo_optimization', 0),
        "total_score": evaluation.get('total_score', 0),
        "quality_feedback": json.dumps(evaluation.get('feedback', {}), ensure_ascii=False),
        "evaluator": "gemini-api"
    }

    try:
        response = requests.post(url, json=payload)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"âŒ API ì €ì¥ ì‹¤íŒ¨: {e}")
        raise

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ëª…ë ¹ì¤„ ì¸ì: íŒŒì¼ ê²½ë¡œ ë˜ëŠ” ë¸”ë¡œê·¸ ID
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•:")
        print("  python evaluate_quality.py <content.json>  # JSON íŒŒì¼ë¡œ í‰ê°€")
        print("  python evaluate_quality.py --id <blog_id>  # APIì—ì„œ ì¡°íšŒí•˜ì—¬ í‰ê°€")
        sys.exit(1)

    # API ëª¨ë“œ vs íŒŒì¼ ëª¨ë“œ
    use_api = False
    blog_id = None
    content = None

    if sys.argv[1] == "--id":
        if len(sys.argv) < 3:
            print("âŒ ë¸”ë¡œê·¸ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            sys.exit(1)
        use_api = True
        blog_id = sys.argv[2]
    else:
        content_file = sys.argv[1]

    try:
        # APIì—ì„œ ë¸”ë¡œê·¸ ì¡°íšŒ
        if use_api:
            print(f"\nğŸ” APIì—ì„œ ë¸”ë¡œê·¸ ID {blog_id} ì¡°íšŒ ì¤‘...")
            blog_data = fetch_blog_from_api(blog_id)

            # í‰ê°€ìš© ì½˜í…ì¸  êµ¬ì„±
            content = {
                "title": blog_data.get("title"),
                "slug": blog_data.get("slug"),
                "content": blog_data.get("content"),
                "excerpt": blog_data.get("excerpt"),
                "keywords": blog_data.get("keywords")
            }
            print(f"âœ… ë¸”ë¡œê·¸ ì¡°íšŒ ì™„ë£Œ: {content['title']}")

        # íŒŒì¼ì—ì„œ ë¡œë“œ
        else:
            with open(content_file, 'r', encoding='utf-8') as f:
                content = json.load(f)

        # í’ˆì§ˆ í‰ê°€
        evaluation = evaluate_content(content)

        # ê²°ê³¼ ì¶œë ¥
        print_evaluation_summary(evaluation)

        # ë°œí–‰ ì—¬ë¶€ íŒë‹¨
        can_publish, reason = should_publish(evaluation)

        # API ëª¨ë“œì¸ ê²½ìš° ê²°ê³¼ ì €ì¥
        if use_api:
            print(f"\nğŸ’¾ APIì— í‰ê°€ ê²°ê³¼ ì €ì¥ ì¤‘...")
            api_response = save_evaluation_to_api(blog_id, evaluation)

            print(f"âœ… í‰ê°€ ê²°ê³¼ ì €ì¥ ì™„ë£Œ!")
            if api_response.get('auto_published'):
                print(f"ğŸ‰ ìë™ ë°œí–‰ ì™„ë£Œ! (is_published = true)")
            elif api_response.get('is_published'):
                print(f"â„¹ï¸  ì´ë¯¸ ë°œí–‰ëœ ê¸€ì…ë‹ˆë‹¤.")
            else:
                print(f"â³ ë¯¸ë°œí–‰ ìƒíƒœ ìœ ì§€ (í’ˆì§ˆ ê¸°ì¤€ ë¯¸ë‹¬)")

        # ìµœì¢… íŒì •
        if can_publish:
            print("\nâœ… ë°œí–‰ ìŠ¹ì¸! í’ˆì§ˆ ê¸°ì¤€ì„ ëª¨ë‘ ì¶©ì¡±í•©ë‹ˆë‹¤.")
            exit(0)
        else:
            print(f"\nâŒ ë°œí–‰ ê±°ë¶€: {reason}")
            print("   ì½˜í…ì¸ ë¥¼ ìˆ˜ì •í•˜ê±°ë‚˜ ì¬ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.")
            exit(1)

    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {content_file}")
        exit(1)
    except json.JSONDecodeError:
        print(f"âŒ JSON íŒŒì¼ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤")
        exit(1)
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        exit(1)

if __name__ == "__main__":
    main()
